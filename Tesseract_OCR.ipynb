{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+amRbQqItQhvhD9a1KJAe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEEMANTULANISCHAL/AgroMart-Final/blob/main/Tesseract_OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf4LlENMjKsq",
        "outputId": "ed7df866-4b15-4f86-bf8e-553ba837bc7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/274.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/274.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.8.0+cu101 (from versions: 1.11.0, 1.11.0+cpu, 1.11.0+cu102, 1.11.0+cu113, 1.11.0+cu115, 1.11.0+rocm4.3.1, 1.11.0+rocm4.5.2, 1.12.0, 1.12.0+cpu, 1.12.0+cu102, 1.12.0+cu113, 1.12.0+cu116, 1.12.0+rocm5.0, 1.12.0+rocm5.1.1, 1.12.1, 1.12.1+cpu, 1.12.1+cu102, 1.12.1+cu113, 1.12.1+cu116, 1.12.1+rocm5.0, 1.12.1+rocm5.1.1, 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.0+cu117.with.pypi.cudnn, 1.13.0+rocm5.1.1, 1.13.0+rocm5.2, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 1.13.1+cu117.with.pypi.cudnn, 1.13.1+rocm5.1.1, 1.13.1+rocm5.2, 2.0.0, 2.0.0+cpu, 2.0.0+cpu.cxx11.abi, 2.0.0+cu117, 2.0.0+cu117.with.pypi.cudnn, 2.0.0+cu118, 2.0.0+rocm5.3, 2.0.0+rocm5.4.2, 2.0.1, 2.0.1+cpu, 2.0.1+cpu.cxx11.abi, 2.0.1+cu117, 2.0.1+cu117.with.pypi.cudnn, 2.0.1+cu118, 2.0.1+rocm5.3, 2.0.1+rocm5.4.2, 2.1.0, 2.1.0+cpu, 2.1.0+cpu.cxx11.abi, 2.1.0+cu118, 2.1.0+cu121, 2.1.0+cu121.with.pypi.cudnn, 2.1.0+rocm5.5, 2.1.0+rocm5.6, 2.1.1, 2.1.1+cpu, 2.1.1+cpu.cxx11.abi, 2.1.1+cu118, 2.1.1+cu121, 2.1.1+cu121.with.pypi.cudnn, 2.1.1+rocm5.5, 2.1.1+rocm5.6, 2.1.2, 2.1.2+cpu, 2.1.2+cpu.cxx11.abi, 2.1.2+cu118, 2.1.2+cu121, 2.1.2+cu121.with.pypi.cudnn, 2.1.2+rocm5.5, 2.1.2+rocm5.6, 2.2.0, 2.2.0+cpu, 2.2.0+cpu.cxx11.abi, 2.2.0+cu118, 2.2.0+cu121, 2.2.0+rocm5.6, 2.2.0+rocm5.7)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.8.0+cu101\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement detectron2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for detectron2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml==5.1\n",
        "!pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install -q detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
        "!pip install -q pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aLrTwYPksB8",
        "outputId": "c112da82-b7cb-4734-88c6-2a078816f948"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.17.1 dill-0.3.8 multiprocess-0.70.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueDeIZtZkyAK",
        "outputId": "59ef3c39-e758-4836-dfa7-72ea1fe621ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 0s (23.9 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from skimage.filters import frangi\n",
        "from transformers import LayoutLMv2FeatureExtractor, LayoutLMv2TokenizerFast, LayoutLMv2ForTokenClassification\n",
        "from datasets import load_dataset\n",
        "import pytesseract\n",
        "from PIL import Image, ImageFont, ImageDraw"
      ],
      "metadata": {
        "id": "dmbK8FJ9k1Wx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_contours(image_path):\n",
        "  img = cv2.imread(image_path)\n",
        "\n",
        "  # Apply bilateral filter\n",
        "  img_bilateral = cv2.bilateralFilter(img, 9, 75, 75)\n",
        "\n",
        "  # Convert the image to grayscale\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Apply thresholding to remove text and noise\n",
        "  _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "  # Apply ROI masking to exclude non-graph regions\n",
        "  mask = np.zeros_like(thresh)\n",
        "  mask[50:400, 100:700] = 255\n",
        "  masked_thresh = cv2.bitwise_and(thresh, mask)\n",
        "\n",
        "  # Apply edge detection using the Canny algorithm\n",
        "  edges = cv2.Canny(gray, 100, 200)\n",
        "\n",
        "  # Apply horizontal line detection using HoughLinesP\n",
        "  lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=250, maxLineGap=15)\n",
        "  horizontal_lines = []\n",
        "  for line in lines:\n",
        "      x1, y1, x2, y2 = line[0]\n",
        "      if abs(y1 - y2) < 5: # Check if the line is horizontal\n",
        "          horizontal_lines.append(line)\n",
        "\n",
        "  # Draw the detected lines on the image\n",
        "  for line in horizontal_lines:\n",
        "      x1, y1, x2, y2 = line[0]\n",
        "      # cv2.line(img, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
        "      # Find contours in the image\n",
        "  contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  # Filter out unwanted contours based on contour area and aspect ratio\n",
        "  bars = []\n",
        "  for cnt in contours:\n",
        "      area = cv2.contourArea(cnt)\n",
        "      x, y, w, h = cv2.boundingRect(cnt)\n",
        "      aspect_ratio = float(w) / h\n",
        "      if area > 7 and aspect_ratio > 5 and aspect_ratio < 50000:\n",
        "          bars.append(cnt)\n",
        "\n",
        "  ###### 2 consecutive element from the bars represent single contour only\n",
        "  ###### and we will consider only one of them, so we will filter out odd index elemnts from the \"bars\"\n",
        "\n",
        "  def filter_bars(bars):\n",
        "    lst = []\n",
        "    for i in range(len(bars)):\n",
        "      if(i%2==1):\n",
        "        lst.append(bars[i])\n",
        "    return lst\n",
        "\n",
        "  bars = filter_bars(bars)\n",
        "\n",
        "  # Draw the remaining contours on the image\n",
        "  cv2.drawContours(img, bars, -1, (255, 255, 0), 2)\n",
        "\n",
        "  # Show the image\n",
        "  cv2_imshow(img)\n",
        "  return bars\n"
      ],
      "metadata": {
        "id": "Y2OMlB-Ak4zx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_topright_corner(bars):\n",
        "  topright_corner = []\n",
        "  for bar in bars:\n",
        "    x, y, w, h = cv2.boundingRect(bar)\n",
        "    topright_corner.append([x+w,y])\n",
        "  return topright_corner\n",
        "\n",
        "# contours_right_coords"
      ],
      "metadata": {
        "id": "JIhPLiEdlBUA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadFromLayoutlmv2():\n",
        "  feature_extractor = LayoutLMv2FeatureExtractor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")# apply_ocr is set to True by default\n",
        "  tokenizer = LayoutLMv2TokenizerFast.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\n",
        "  model = LayoutLMv2ForTokenClassification.from_pretrained(\"nielsr/layoutlmv2-finetuned-funsd\")\n",
        "  return feature_extractor,tokenizer,model\n",
        "\n",
        "def labelForBoxes():\n",
        "  dataset = load_dataset(\"nielsr/funsd\", split=\"test\")\n",
        "  # define id2label, label2color\n",
        "  labels = dataset.features['ner_tags'].feature.names\n",
        "  id2label = {v: k for v, k in enumerate(labels)}\n",
        "  label2color = {'question':'blue', 'answer':'green', 'header':'orange', 'other':'violet'}\n",
        "  return id2label, label2color\n",
        "\n",
        "def unnormalize_box(bbox, width, height):\n",
        "     return [\n",
        "         width * (bbox[0] / 1000),\n",
        "         height * (bbox[1] / 1000),\n",
        "         width * (bbox[2] / 1000),\n",
        "         height * (bbox[3] / 1000),\n",
        "     ]\n",
        "\n",
        "def iob_to_label(label):\n",
        "    label = label[2:]\n",
        "    if not label:\n",
        "      return 'other'\n",
        "    return label\n",
        "\n",
        "def process_image(image,id2label,label2color,feature_extractor,tokenizer,model):\n",
        "\n",
        "    # Convert the image to RGB format\n",
        "    image = image.convert('RGB')\n",
        "    width, height = image.size\n",
        "\n",
        "    # get words, boxes\n",
        "    encoding_feature_extractor = feature_extractor(image, return_tensors=\"pt\")\n",
        "    words, boxes = encoding_feature_extractor.words, encoding_feature_extractor.boxes\n",
        "    # encode\n",
        "    encoding = tokenizer(words, boxes=boxes, truncation=True, return_offsets_mapping=True, return_tensors=\"pt\")\n",
        "    offset_mapping = encoding.pop('offset_mapping')\n",
        "    encoding[\"image\"] = encoding_feature_extractor.pixel_values\n",
        "    # forward pass\n",
        "    outputs = model(**encoding)\n",
        "    # get predictions\n",
        "    predictions = outputs.logits.argmax(-1).squeeze().tolist()\n",
        "    token_boxes = encoding.bbox.squeeze().tolist()\n",
        "    # only keep non-subword predictions\n",
        "    is_subword = np.array(offset_mapping.squeeze().tolist())[:,0] != 0\n",
        "    true_predictions = [id2label[pred] for idx, pred in enumerate(predictions) if not is_subword[idx]]\n",
        "    true_boxes = [unnormalize_box(box, width, height) for idx, box in enumerate(token_boxes) if not is_subword[idx]]\n",
        "    # draw predictions over the image\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.load_default()\n",
        "    for prediction, box in zip(true_predictions, true_boxes):\n",
        "        predicted_label = iob_to_label(prediction).lower()\n",
        "        draw.rectangle(box, outline=label2color[predicted_label])\n",
        "        draw.text((box[0]+10, box[1]-10), text=predicted_label, fill=label2color[predicted_label], font=font)\n",
        "    return image,true_boxes,words,true_predictions,true_boxes,is_subword"
      ],
      "metadata": {
        "id": "cCgg8n_flGrK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_bbox(bboxes,img):\n",
        "  # removing the fist and last coordinates\n",
        "  bboxes= bboxes[1:-1]\n",
        "\n",
        "  # Define the new image size\n",
        "  new_width = 100\n",
        "  new_height = 100\n",
        "\n",
        "  original_width,original_height = img.size\n",
        "  # Calculate the scaling factors\n",
        "  x_scale = new_width / original_width\n",
        "  y_scale = new_height / original_height\n",
        "\n",
        "  #parsing the bboxes\n",
        "  new_bboxes = []\n",
        "  for bbox in bboxes:\n",
        "    x1,y1,x2,y2 = bbox\n",
        "    # Normalize the bounding box coordinates\n",
        "    new_x1 = int(x1 * x_scale)\n",
        "    new_y1 = int(y1 * y_scale)\n",
        "    new_x2 = int(x2 * x_scale)\n",
        "    new_y2 = int(y2 * y_scale)\n",
        "\n",
        "    new_bbox = new_x1,new_y1,new_x2,new_y2\n",
        "    new_bboxes.append(new_bbox)\n",
        "  return new_bboxes"
      ],
      "metadata": {
        "id": "0kDPXN2ulPN8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######### categorize the words into \"keys, values, headers\"\n",
        "\n",
        "def graph_categorizer(words,bboxes,img):\n",
        "\n",
        "  output_dict = {\"headers\":[],\"keys\":[],\"values\":[]}\n",
        "\n",
        "  bboxes = normalize_bbox(bboxes,img)\n",
        "\n",
        "  for idx in range(len(words[0])):\n",
        "    x1,y1,x2,y2 = bboxes[idx]\n",
        "    ###### header\n",
        "    if(y2<=13):\n",
        "      output_dict['headers'].append(words[0][idx])\n",
        "    ###### keys\n",
        "    elif(x2<43):\n",
        "      output_dict['keys'].append(words[0][idx])\n",
        "    ###### values\n",
        "    elif(x2>=43):\n",
        "      output_dict['values'].append(words[0][idx])\n",
        "\n",
        "  return output_dict"
      ],
      "metadata": {
        "id": "sUhfx92SlTMY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def is_numeric_adv(text):\n",
        "  pattern = r'\\d+\\.?\\d+'  # regular expression pattern to match numerical values\n",
        "\n",
        "  matches = re.findall(pattern, text)  # find all numerical values in the text string\n",
        "\n",
        "  if(len(matches)):\n",
        "    return True\n",
        "  return False\n"
      ],
      "metadata": {
        "id": "5T47lBG0lWMB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######## merge close words\n",
        "\n",
        "def merge_close_words(words,bboxes,image):\n",
        "\n",
        "\n",
        "  nbboxes = normalize_bbox(bboxes,image)\n",
        "  categorized_text = graph_categorizer(words,bboxes,image)\n",
        "\n",
        "  words_to_bbox = {}\n",
        "  bboxes = bboxes[1:-1]\n",
        "  for idx in range(len(words[0])):\n",
        "    if(words[0][idx] in categorized_text['headers']  or words[0][idx] in categorized_text['keys']):\n",
        "      if words[0][idx] not in  words_to_bbox:\n",
        "        words_to_bbox[words[0][idx]] = bboxes[idx]\n",
        "  # print(words_to_bbox)\n",
        "\n",
        "  parsed_idx = []\n",
        "  parsed_words = []\n",
        "  for idx in range(len(words[0])):\n",
        "    if(idx in parsed_idx or words[0][idx] in parsed_words):\n",
        "      continue\n",
        "    if((words[0][idx] in categorized_text['headers']  or words[0][idx] in categorized_text['keys']) and (is_numeric_adv(words[0][idx])==False)):\n",
        "      x1,y1,x2,y2 = nbboxes[idx]\n",
        "      # print([words[0][idx]], nbboxes[idx])\n",
        "      parsed_words.append(words[0][idx])\n",
        "      ori_x1,ori_y1,ori_x2,ori_y2 = words_to_bbox[words[0][idx]]\n",
        "\n",
        "      lower_10th_no = (y2//10) * 10\n",
        "      higher_10th_no = lower_10th_no + 10\n",
        "      return words_to_bbox\n"
      ],
      "metadata": {
        "id": "yZ_myppTlZH2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bboxes(bboxes,image_path):\n",
        "  # Load input image\n",
        "  img = cv2.imread(image_path)\n",
        "\n",
        "  for bbox in bboxes:\n",
        "    # print(bbox)\n",
        "    # print((int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])))\n",
        "\n",
        "    # Draw rectangle on image\n",
        "    color = (0, 255, 0)  # BGR color tuple for the rectangle (green in this case)\n",
        "    thickness = 2  # thickness of the rectangle border\n",
        "    cv2.rectangle(img, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), color, thickness)\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "NIj3zvufmOJL"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}